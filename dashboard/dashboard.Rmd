---
title: "HPC Usage"
date: '`r format(Sys.Date()-1, "%B %d, %Y")`'
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    source: embed
    smart: false
    navbar:
      - { title: "Annual Usage", href: "https://webapps.lehigh.edu/hpc/usage/annualusage.html"}
      - { title: "HPC Training", href: "https://webapps.lehigh.edu/hpc/training/training.html"}
      - { title: "Daily Monitoring", href: "https://webapps.lehigh.edu/hpc/monitor"}
      - { title: "System Status", href: "https://rcstatus.cc.lehigh.edu"}
---

```{css, echo=F}
/*
.dataTables_scrollBody {
    height:600px !important;
    max-height:600px !important;
}
.chart-stage-flex {
    overflow:auto !important;
}
*/
```


```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(lubridate)
library(dygraphs)
library(shiny)
library(xts)
library(DT)
library(plotly)

# read usage by partition and clean data
# New partition  -> add 2 to seq_len
data <- read.table('/home/alp514/usage/daily.csv', header = FALSE, sep = ",", col.names = paste0("V",seq_len(37)), fill = TRUE)
data[is.na(data)] <- 0
datagpu <- read.table('/home/alp514/usage/dailygpu.csv', header = FALSE, sep = ",", col.names = paste0("V",seq_len(15)), fill = TRUE)
datagpu[is.na(datagpu)] <- 0

# read daily usage reports
daily1617 <- read_delim('/home/alp514/dashboard/soldaily1617.csv', delim=";")
daily1718 <- read_delim('/home/alp514/dashboard/soldaily1718.csv', delim=";")
daily1819 <- read_delim('/home/alp514/dashboard/soldaily1819.csv', delim=";")
daily1920 <- read_delim('/home/alp514/dashboard/soldaily1920.csv', delim=";")
daily2021 <- read_delim('/home/alp514/dashboard/soldaily2021.csv', delim=";")
daily2122 <- read_delim('/home/alp514/dashboard/soldaily2122.csv', delim=";")
#daily2223 <- read_delim('/home/alp514/dashboard/soldaily2223.csv', delim=";")

daily <- rbind(daily1617,daily1718,daily1819,daily1920,daily2021,daily2122)
# daily <- rbind(daily1617,daily1718,daily1819,daily1920,daily2021,daily2122,daily2223)

# get usage for last 14 days
fortnight <- daily %>%
filter(as.Date(Day) > today() - 15 )

# read power and energy usage
dailypower1617 <- read_csv('/home/alp514/dashboard/dailypower1617.csv') %>% mutate(Power=Energy/24) %>% select(c(Date,Power,Energy))
dailypower <- read_csv('/home/alp514/dashboard/dailypower.csv') %>%
  group_by(Date) %>% summarize(Power=sum(Power), Energy=sum(Energy))
dailypower <- rbind(dailypower1617,dailypower)
monthlypower <- read_csv('/home/alp514/dashboard/monthlypower.csv') %>% 
  group_by(Month) %>% summarize(Power=sum(Power), Energy=sum(Energy))
fortnightpower <- dailypower %>%
  filter(as.Date(Date) > today() - 15 )

# Filters for ay and cy
ay1617filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2016-10-01") & Month < as.Date("2017-10-01"))
}
ay1718filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2017-10-01") & Month < as.Date("2018-10-01"))
}
ay1819filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2018-10-01") & Month < as.Date("2019-10-01"))
}
ay1920filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2019-10-01") & Month < as.Date("2020-10-01"))
}
ay2021filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2020-10-01") & Month < as.Date("2021-10-01"))
}
ay2122filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2021-10-01") & Month < as.Date("2022-10-01"))
}
ay2223filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2022-10-01") & Month < as.Date("2023-10-01"))
}
cy2016filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2016-01-01") & Month < as.Date("2017-01-01"))
}
cy2017filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2017-01-01") & Month < as.Date("2018-01-01"))
}
cy2018filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2018-01-01") & Month < as.Date("2019-01-01"))
}
cy2019filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2019-01-01") & Month < as.Date("2020-01-01"))
}
cy2020filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2020-01-01") & Month < as.Date("2021-01-01"))
}
cy2021filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2021-01-01") & Month < as.Date("2022-01-01"))
}
cy2022filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2022-01-01") & Month < as.Date("2023-01-01"))
}
cy2023filter <- function(data) {
  data %>%
   filter(Month >= as.Date("2023-01-01") & Month < as.Date("2024-01-01"))
}

currentDate <- Sys.Date()
yesterday <- currentDate - 1

day_of_month <- mday(today())
days_this_month <- days_in_month(as.Date(cut(Sys.Date(), "month")))
days_prev_month <- days_in_month(floor_date(currentDate - days(day(currentDate)),"month"))

if ( day_of_month < 2 ){
  days_sofar <- as.double(days_prev_month[[1]])
  days_this_month <- days_prev_month
  thismonth <- daily %>%
    filter(as.Date(Day) >= floor_date(currentDate - days(day(currentDate)),"month") & as.Date(Day) < as.Date(cut(currentDate,"month")))
  prevmonth <- daily %>%
    filter(as.Date(Day) >= floor_date(currentDate - days(day(currentDate)),"month") & as.Date(Day) < as.Date(cut(currentDate,"month")))
} else {
  days_sofar <- mday(today()) - 1
  thismonth <- daily %>%
    filter(as.Date(Day) >= as.Date(cut(currentDate,"month")))
  prevmonth <- daily %>%
    filter(as.Date(Day) >= floor_date(currentDate - days(day(currentDate)),"month") & as.Date(Day) < as.Date(cut(currentDate,"month")))
}


# group usage by month
monthly <- daily %>% 
  group_by(Month=floor_date(as.Date(Day), "month"),Name,Department,PI,PIDept,Status) 

# total available by AY	
ay1617su <- c(580320.00,561600.00,580320.00,580320.00,524160.00,580320.00,699840.00,955296.00,924480.00,955296.00,955296.00,924480.00)
ay1718su <- c(955296.00,924480.00,967200.00,967200.00,873600.00,967200.00,1117440.00,  1154688.00,1117440.00,1154688.00,1155480.00,1169280.00)
ay1819su <- c(1624*31,1696*30,1720*31,2152*31,2152*28,2152*31,2188*30,2188*31,2188*30,2188*31,2188*31,2188*30)*24
ay1920su <- c(2188*31,2188*30,2188*31,2188*31,2188*29,2188*31,2188*30,2188*31,2332*30,2332*31,2404*31,2404*30)*24
ay2021su <- c(2404*31,2404*30,2404*31,4260*31,4260*28,4260*31,4260*30,4260*31,4260*30,4260*31,4260*31,4260*30)*24
ay2122su <- c(4260*31,4260*30,4260*31,4260*31,4260*28,4260*31,4404*30,4404*31,4404*30,4404*31,4404*31,4404*30)*24
# If more resources get added modify this accordingly oct'22 - sep'23
ay2223su <- c(4404*31,4404*30,4404*31,4404*31,4404*28,4404*31,4404*30,4404*31,4404*30,4404*31,4404*31,4404*30)*24

# tatal available by CY
cy2016su <- c(580320.00,561600.00,580320.00)
cy2017su <- c(580320.00,524160.00,580320.00,699840.00,955296.00,924480.00,955296.00,955296.00,924480.00,955296.00,924480.00,967200.00)
cy2018su <- c(967200.00,873600.00,967200.00,1117440.00,  1154688.00,1117440.00,1154688.00,1155480.00,1169280.00,1624*31*24,1696*30*24,1720*31*24)
cy2019su <- c(2152*31,2152*28,2152*31,2188*30,2188*31,2188*30,2188*31,2188*31,2188*30,2188*31,2188*30,2188*31)*24
cy2020su <- c(2188*31,2188*29,2188*31,2188*30,2188*31,2332*30,2332*31,2404*31,2404*30,2404*31,2404*30,2404*31)*24
cy2021su <- c(4260*31,4260*28,4260*31,4260*30,4260*31,4260*30,4260*31,4260*31,4260*30,4260*31,4260*30,4260*31)*24
cy2022su <- c(4260*31,4260*28,4260*31,4404*30,4404*31,4404*30,4404*31,4404*31,4404*30,4404*31,4404*30,4404*31)*24
cy2023su <- c(4404*31,4404*28,4404*31,4404*30,4404*31,4404*30,4404*31,4404*31,4404*30,4404*31,4404*30,4404*31)*24

# cummalative total by AY
aysu <- c(ay1617su,ay1718su,ay1819su,ay1920su,ay2021su,ay2122su)
# aysu <- c(ay1617su,ay1718su,ay1819su,ay1920su,ay2021su,ay2122su,ay2223su)
		
# Details of Sol nodes
# If cpu frequency is reduced
#   Haswell, Broadwell & AMD EPYC provide 16 FLOP per cycle for AVX2 or AVX256 extensions, while
#   Skylake, Cascade Lake provides 32 FLOP per cycle for AVX512 extension
# GFLOPs Performance = FLOPs/cycle * number of cores * cpu freq in GHz 
# As more resource get added, modify below
avx256 <- 16
avx512 <- 32
ltsnodes <- 9
ltscores <- 20
ltsperf <- 2*avx256
im1080nodes <- 25
im1080cores <- 24
im1080perf <- ltsperf
engnodes <- 8
engcores <- 24
engperf <- ltsperf
engcnodes <- 14
engccores <- 24
engcperf <- 1.8*avx256
himemnodes <- 1
himemcores <- 16
himemperf <- 2.2*avx256
engenodes <- 8
engecores <- 36
engeperf <- 1.5*avx512
enginodes <- 2
engicores <- 36
engiperf <- 1.5*avx512
engecnodes <- 2
im2080nodes <- 12
im2080cores <- 36
im2080perf <- 1.5*avx512
im1080gpu <- 72
im2080gpu <- 48
chemnodes <- 4
chemcores <- 36
chemperf <- 1.6*avx512
healthnodes <- 2
healthcores <- 36
healthperf <- 1.6*avx512
hawkcpunodes <- 26
hawkmemnodes <- 4
hawkgpunodes <- 4
infolabnodes <- 2
hawkcpucores <- 52
hawkgpucores <- 48
hawkgpu <- hawkgpunodes * 8
hawkcpuperf <- 1.3*avx512
hawkgpuperf <-  1.3*avx256
piscesnodes <- 1
piscescores <- 48
piscescpuperf <- 2*avx512
piscesgpu <- piscesnodes * 5
piscesgpuperf <- 9.7
piscesmem <- 192
ima40nodes <- 3
ima40cores <- 32
ima40cpuperf <- 2.8*avx256
ima40gpu <- ima40nodes * 8
ima40gpuperf <- 1.17

superyear <- 24*365

lts <- ltsnodes*ltscores*24
im1080 <- im1080nodes*im1080cores*24
eng <- engnodes*engcores*24
engc <- engcnodes*engccores*24
himem <- himemnodes*himemcores*24
enge <- engenodes*engecores*24
engi <- enginodes*engicores*24
im2080 <- im2080nodes*im2080cores*24
chem <- (engecnodes + chemnodes)*chemcores*24
health <- healthnodes*healthcores*24
hawk <- (hawkcpunodes + hawkmemnodes)*hawkcpucores*24 + hawkgpunodes*hawkgpucores*24
infolab <- infolabnodes *hawkcpucores*24 
pisces <- piscesnodes * piscescores*24 
ima40 <- ima40nodes * ima40cores*24 

# number of sus per year
all <- lts + im1080 + eng + engc + himem + enge + engi + im2080 + chem + health + hawk + infolab + pisces + ima40

# number of nodes
solnodes <- ltsnodes + im1080nodes + engnodes + engcnodes + himemnodes + engenodes + enginodes + engecnodes + im2080nodes + chemnodes + healthnodes + infolabnodes + piscesnodes + ima40nodes
hawknodes <- hawkcpunodes + hawkmemnodes + hawkgpunodes
totalnodes <- solnodes + hawknodes

# number of cores
solcores <- ltsnodes*ltscores + (im1080nodes + engnodes)*engcores + engcnodes*engccores + himemnodes*himemcores + (engenodes + enginodes + engecnodes + im2080nodes + chemnodes + healthnodes )*engecores + infolabnodes*hawkcpucores + piscesnodes*piscescores + ima40nodes*ima40cores
hawkcores <- (hawkcpunodes + hawkmemnodes)*hawkcpucores + hawkgpunodes*hawkgpucores
totalcores <- solcores + hawkcores

# cpu memory
solmem <- (ltsnodes + im1080nodes + engnodes) * 128 + engcnodes * 64 + himemnodes * 512 + (engenodes + enginodes + engecnodes + im2080nodes + chemnodes + healthnodes)  * 192 + infolabnodes * 384 + piscesnodes * 192 + ima40nodes * 256
hawkmem <- hawkcpunodes * 384 + hawkmemnodes * 1536 + hawkgpunodes * 192
totalmem <- solmem + hawkmem

# cpu performance
solperf <- (ltsnodes*ltscores*ltsperf + (im1080nodes + engnodes)*im1080cores*im1080perf + engcnodes*engccores*engcperf + himemnodes*himemcores*himemperf + 
     (engenodes+enginodes+engecnodes+im2080nodes)*engecores*engeperf + chemnodes*chemcores*chemperf + healthnodes*healthcores*healthperf)/1000 + 
     infolabnodes*hawkcpucores*hawkcpuperf/1000 + hawkgpunodes*hawkgpucores*hawkgpuperf/1000 + piscesnodes*piscescores*piscescpuperf/1000 + ima40nodes*ima40cores*ima40cpuperf/1000
hawkperf <- (hawkcpunodes + hawkmemnodes)*hawkcpucores*hawkcpuperf/1000 + hawkgpunodes*hawkgpucores*hawkgpuperf/1000
totalperf <- solperf + hawkperf

# gpu memory
solgpumem <- im1080gpu * 8 + im2080gpu * 11 + piscesgpu * 40 + ima40gpu * 48
hawkgpumem <- hawkgpu * 16
gpumem <- solgpumem + hawkgpumem

# number of cuda cores
im1080cuda <- im1080gpu * 2560
im2080cuda <- im2080gpu * 4352
teslat4cuda <- hawkgpu * 2560
piscescuda <- piscesgpu * 6912
ima40cuda <- ima40gpu * 10752

# gpu performance
solgpuperf <- im1080gpu*257/1000 + im2080gpu*367.2/1000 + piscesgpu*piscesgpuperf + ima40gpu*ima40gpuperf
hawkgpuperf <- hawkgpu*253.38/1000
totalgpuperf <- solgpuperf + hawkgpuperf
```

```{r def_func, include=F}
mydygraph <- function(dataset,partlabel) {
dygraph( xts(x = dataset, order.by = d1)) %>%
  dySeries("V1", label = partlabel, color = "black") %>%
  dyAxis("y", label = "SUs consumed") %>%
  dyOptions(stackedGraph = TRUE) %>%
  dyRoller(rollPeriod = 1) %>%
  dyHighlight(highlightSeriesOpts = list(strokeWidth = 3))
} 
```

Last 2 Weeks
=========================================================================

Row
-----------------------------------------------------------------------


```{r fortnight_setup}
users <- fortnight %>%
  group_by(Name) %>%
  summarize(Total=sum(as.double(Total)))
pis <- fortnight %>%
  group_by(PI) %>%
  summarize(Total=sum(as.double(Total)),Jobs=sum(as.double(TotalJ)))
pidept <- fortnight %>%
  group_by(PIDept) %>%
  summarize(Total=sum(as.double(Total)))
dept <- fortnight %>%
  group_by(Department) %>%
  summarize(Total=sum(as.double(Total)))
forttotal <- sum(pis$Total)
fortusage <- round(forttotal/(all*14)*100)
fortjobs <- sum(pis$Jobs)
fortenergy <- round(sum(fortnightpower$Energy)/(1000*1000),2)
```

### Active Users

```{r fortnight_users}
valueBox(n_distinct(users$Name), icon = "fa-users")
```

### Active PIs

```{r fortnight_pis}
valueBox(n_distinct(pis$PI), icon = "fa-user-md")
```

### PI Departments

```{r fortnight_pidept}
valueBox(n_distinct(pidept$PIDept), icon = "fa-building")
```

### Users Major/Department

```{r fortnight_userdept}
valueBox(n_distinct(dept$Department), icon = "fa-university")
```

### Jobs Run

```{r fornight_jobsrun}
valueBox(fortjobs, icon = "fa-desktop")
```

### % of SUs consumed

```{r fornight_sus}
gauge(fortusage, min = 0, max = 100, symbol = '%', gaugeSectors(
  success = c(71, 100), warning = c(50, 70), danger = c(0, 49)
))
```


Row {.tabset}
--------------------------------------------------------------------

### HPC Clusters 
#### HPC provides two Clusters, Sol and Hawk with a total of `r totalnodes` nodes.

* Sol is a `r solnodes` node heterogeneous cluster launched on Oct 1, 2016 initially with `r ltsnodes+im1080nodes` nodes.
   * `r solcores` CPUs with `r sprintf("%4.2f",solmem/1000)`TB memory providing a total performance of `r solperf` TFLOPs.
   * `r im1080gpu+im2080gpu+piscesgpu+ima40gpu` GPUs (`r sprintf("%6d",im1080cuda+im2080cuda+piscescuda+ima40cuda)` CUDA Cores) with `r sprintf("%d",solgpumem)`GB memory providing a total performance of `r solgpuperf` TFLOPs.
   * Total Performance (frequency scaled for full AVX2/AVX512 support): `r solperf+solgpuperf` TFLOPs
   * SUs available: `r sprintf("%d", solcores*24)` daily or `r sprintf("%d", solcores*superyear)` annually
* Hawk, an NSF Campus Cyberinfrastructure award funded `r hawknodes` node hybrid cluster put into production on Feb 1, 2021
   * `r hawkcores` CPUs with `r sprintf("%4.2f",hawkmem/1000)`TB memory providing a total performance of `r hawkperf` TFLOPs.
   * `r hawkgpu` GPUs (`r sprintf("%6d",teslat4cuda)` CUDA Cores) with `r hawkgpu*16`GB memory providing a total performance of `r hawkgpuperf` TFLOPs.
   * Total Performance (frequency scaled for full AVX2/AVX512 support): `r hawkperf+hawkgpuperf` TFLOPs
   * SUs available: `r sprintf("%d", hawkcores*24)` daily or `r sprintf("%d", hawkcores*superyear)` annually

* Total Performance
   * `r totalcores` CPUs with `r sprintf("%4.2f",totalmem/1000)`TB memory providing a total performance of `r totalperf` TFLOPs.
   * `r im1080gpu+im2080gpu+hawkgpu+piscesgpu+ima40gpu` GPUs (`r sprintf("%6d",im1080cuda+im2080cuda+teslat4cuda+piscescuda+ima40cuda)` CUDA Cores) with `r sprintf("%d",gpumem)`GB memory providing a total performance of `r totalgpuperf` TFLOPs.
   * Total Performance (frequency scaled for full AVX2/AVX512 support): `r totalperf+totalgpuperf` TFLOPs
   * SUs available: `r sprintf("%d", totalcores*24)` daily or `r sprintf("%d", totalcores*superyear)` annually


### Total Usage

```{r fortnighthpcusage_setup}
# create time series for dygraphs
days <- length(data$V1)
d1 <- seq(as.POSIXct(data[1,1]), by = "days", length = days)

solmetric <- data$V2

#dateWindow = c(today() - 30 , today() - 1 )
dateWindow = c(as.Date("2016-08-08"), today() - 1 )

solmetric <- data$V2
mydygraph(solmetric, "Total") %>% 
  dyRoller(rollPeriod = 30) %>% 
  dyRangeSelector( dateWindow = dateWindow ) %>%
  dyEvent("2016-10-01", "Sol launched with 34 nodes, 760 cores", labelLoc = "top") %>% 
  dyEvent("2017-01-19", "34 nodes, 760 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-03-15", "42 nodes, 972 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-05-01", "55 nodes, 1284 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-11-15", "56 nodes, 1300 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-12-01", "56 nodes, 1300 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-04-02", "63 nodes, 1552 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-08-31", "65 nodes, 1624 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-11-12", "66 nodes, 1648 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-12-01", "68 nodes, 1720 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2019-01-02", "80 nodes, 2152 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2019-04-01", "81 nodes, 2188 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-05-31", "85 nodes, 2332 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-08-01", "87 nodes, 2404 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-11-12", "Hawk: User Friendly", labelLoc = "top") %>%
  dyEvent("2022-04-05", "127 nodes, 4404 cores, 181 GPUs", labelLoc = "top")
```

### GPU Usage

```{r}
days <- length(datagpu$V1)
d1 <- seq(as.POSIXct(datagpu[1,1]), by = "days", length = days)

solmetric <- datagpu$V2 + datagpu$V4 + datagpu$V6 + datagpu$V8 + datagpu$V10
dateWindow = c(as.Date("2017-01-19"), today() - 1 )
mydygraph(solmetric, "Total") %>%
  dyRoller(rollPeriod = 30) %>%
  dyRangeSelector( dateWindow = dateWindow ) %>%
  dyEvent("2016-10-01", "Sol launched with 34 nodes, 760 cores", labelLoc = "top") %>% 
  dyEvent("2017-01-19", "34 nodes, 760 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-03-15", "42 nodes, 972 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-05-01", "55 nodes, 1284 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-11-15", "56 nodes, 1300 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-12-01", "56 nodes, 1300 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-04-02", "63 nodes, 1552 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-08-31", "65 nodes, 1624 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-11-12", "66 nodes, 1648 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-12-01", "68 nodes, 1720 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2019-01-02", "80 nodes, 2152 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2019-04-01", "81 nodes, 2188 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-05-31", "85 nodes, 2332 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-08-01", "87 nodes, 2404 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-11-12", "Hawk: User Friendly", labelLoc = "top") 
```

### Energy Consumption

```{r}
dateWindow = c(as.Date("2017-05-01") , today() + 31 )
dygraph( xts(cbind(dailypower$Energy), order.by = dailypower$Date)) %>%
  dySeries("V1", label = "Energy", color = "black") %>%
  dyAxis("y", label = "Average Daily Energy consumption (Wh)") %>%
  dyOptions(stackedGraph = TRUE, axisLineWidth = 1.5, fillGraph = TRUE, drawGrid = FALSE, labelsKMB = TRUE) %>%
  dyHighlight(highlightSeriesOpts = list(strokeWidth = 3)) %>%
  dyLegend(width = 400) %>%
  dyRoller(rollPeriod = 14) %>%
  dyEvent("2016-10-01", "Sol launched with 34 nodes, 760 cores", labelLoc = "top") %>% 
  dyEvent("2017-01-19", "34 nodes, 760 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-03-15", "42 nodes, 972 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-05-01", "55 nodes, 1284 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-11-15", "56 nodes, 1300 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-12-01", "56 nodes, 1300 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-04-02", "63 nodes, 1552 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-08-31", "65 nodes, 1624 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-11-12", "66 nodes, 1648 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-12-01", "68 nodes, 1720 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2019-01-02", "80 nodes, 2152 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2019-04-01", "81 nodes, 2188 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-05-31", "85 nodes, 2332 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-08-01", "87 nodes, 2404 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-11-12", "Hawk: User Friendly", labelLoc = "top") %>%
  dyEvent("2021-02-01", "Hawk in Production", labelLoc = "top") %>%
  dyEvent("2022-04-05", "127 nodes, 4404 cores, 181 GPUs", labelLoc = "top") %>%
  dyRangeSelector( dateWindow = dateWindow)
```

```{r topuser_setup}
topuserstotal <- function(data, n = 10) {
data %>%
  group_by(Name,Department,PI,PIDept,Status) %>%
  summarize(Total=sum(round(as.double(Total)))) %>%
  arrange(desc(Total)) %>% head(n) %>%
  datatable(rownames=FALSE,options=list(dom='t', autoWidth = FALSE),extensions = 'Responsive')
}
topusersjobs <- function(data, n = 10) {
data %>%
  group_by(Name,Department,PI,PIDept,Status) %>%
  summarize(Jobs=sum(round(as.double(TotalJ)))) %>%
  arrange(desc(Jobs)) %>% head(n) %>%
  datatable(rownames=FALSE,options=list(dom='t', autoWidth = FALSE),extensions = 'Responsive')
}
toppis <- function(data, n) {
if (missing(n)){
  n <- 10
}
data %>%
  group_by(PI,PIDept) %>%
  summarize(SUs=sum(round(as.double(Total))),Jobs=sum(round(as.double(TotalJ)))) %>%
  arrange(desc(SUs)) %>% head(n) %>%
  datatable(rownames=FALSE,options=list(dom='t', autoWidth = FALSE),extensions = 'Responsive')
}

```


### Top 10 Users by SUs consumed

```{r fortnight_usersus}
fortnight %>% topuserstotal 
```


### Top 10 Users by Jobs 

```{r fortnight_userjobs}
fortnight %>% topusersjobs
```

### AWS Comparison

```{r aws_sol, fig.width=7, fig.height=5}
knitr::include_graphics('/home/alp514/dashboard/sol_value.jpg')
```


Row {data-height=450}
-----------------------------------------------------------------------

### Sol

```{r fortnightsolusage_setup}
# create time series for dygraphs
days <- length(data$V1)
d1 <- seq(as.POSIXct(data[1,1]), by = "days", length = days)

dateWindow = c(today() - 30 , today() - 1 )
#dateWindow = c(as.Date("2016-10-01"), today() - 1 )

solmetric <- data$V4+data$V6+data$V8+data$V10+data$V12+data$V14+data$V16+data$V18+data$V20+data$V22+data$V24+data$V32
mydygraph(solmetric, "Total") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Sol is a `r solnodes` node heterogeneous cluster launched on Oct 1, 2016 initially with `r ltsnodes+im1080nodes` nodes.

* 1 Interactive node: Two 2.3GHz 10-core Intel Xeon E5-2650 v3, 25M Cache, 128GB 2133MHz RAM
* `r ltsnodes` Compute Nodes: Two 2.3GHz 10-core Intel Xeon E5-2650 v3, 25M Cache, 128GB 2133MHz RAM
   * EVGA Geforce GTX 1080 PCIE 8GB GDDR5 (2x on 1 node and 1x on 8 nodes)
* `r im1080nodes+engnodes` Compute Nodes: Two 2.3GHz 12-core Intel Xeon E5-2670 v3, 30M Cache, 128GB 2133MHz RAM
   * EVGA Geforce GTX 1080 PCIE 8GB GDDR5 (2x on 29 nodes and 1x on 4 nodes)
* `r engcnodes` Compute Nodes: Two 2.2GHz 12-core Intel Xeon E5-2650 v4, 30M Cache, 64GB 2133MHz RAM
* `r himemnodes` Compute Node: Two 2.6GHz 8-core Intel Xeon E5-2640 v3, 20M Cache, 512GB 2400MHz RAM
* `r engenodes+enginodes+engecnodes+im2080nodes` Compute Nodes: Two 2.3GHz 18-core Intel Xeon Gold 6140, 24.75M Cache, 192GB 2666MHz RAM
   * ASUS Geforce RTX 2080 TI PCIE 11GB GDDR5 (4x on 12 nodes)
* `r chemnodes+healthnodes` Compute Nodes: Two 2.6GHz 18-core Intel Xeon Gold 6240, 24.75M Cache, 192GB 2933MHz RAM
* `r infolabnodes` Compute Nodes: Two 2.1Gz 26-core Intel Xeon Gold 6230R, 35.75M Cache, 384GB 2933MHz RAM
* `r piscesnodes` Compute Node: Two 3.0GHz 24-core Intel Xeon Gold 6248R, 35.75M Cache, 192GB 4000MHz RAM
   * 5x NVIDIA A100 PCIE 40GB HBM2e
* `r ima40nodes` Compute Nodes: Two 3.0GHz 16-core AMD EPYC 7302, 128M Cache, 3000MHz RAM
   * 8x NVIDIA A40 PCIE 48GB GDDR6

* Nodes contain
   * 1TB HDD
   * 100 Gb/s EDR Infiniband network interface (except infolab nodes)
   * 10 GbE and 1 GbE network interface
   * CentOS 8.x  

Row {data-height=450}
-----------------------------------------------------------------------

### Hawk

```{r fortnighthawkusage_setup}
# create time series for dygraphs
days <- length(data$V1)
d1 <- seq(as.POSIXct(data[1,1]), by = "days", length = days)


dateWindow = c(today() - 30 , today() - 1 )
#dateWindow = c(as.Date("2020-11-11"), today() - 1 )

solmetric <- data$V26+data$V28+data$V30
mydygraph(solmetric, "Total") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Hawk, an NSF Campus Cyberinfrastructure award funded `r hawknodes` node hybrid cluster put into production on Feb 1, 2021

* `r hawkcpunodes` Compute Nodes: Two 2.1Gz 26-core Intel Xeon Gold 6230R, 35.75M Cache, 384GB 2933MHz RAM
* `r hawkmemnodes` Compute Nodes: Two 2.1Gz 26-core Intel Xeon Gold 6230R, 35.75M Cache, 1536GB 2933MHz RAM
* `r hawkgpunodes` Compute Nodes: Two 2.2Gz 24-core Intel Xeon Gold 5220R, 35.75M Cache, 192GB 2933MHz RAM
   * 8x NVIDIA Tesla T4 PCIE 16GB GDDR6

* All Nodes contain
   * 1TB HDD
   * 10 GbE and 1 GbE network interface
   * CentOS 8.x  

* Total Performance
   * `r hawkcores` CPUs with `r sprintf("%4.2f",hawkmem/1000)`TB memory providing a total performance of `r hawkperf` TFLOPs.
   * `r hawkgpu` GPUs (`r sprintf("%6d",teslat4cuda)` CUDA Cores) with `r hawkgpu*16`GB memory providing a total performance of `r hawkgpuperf` TFLOPs.
   * Total Performance (frequency scaled for full AVX2/AVX512 support): `r hawkperf+hawkgpuperf` TFLOPs
   * SUs available: `r sprintf("%d", hawkcores*24)` daily or `r sprintf("%d", hawkcores*superyear)` annually


Row {data-height=240}
-----------------------------------------------------------------------

### lts

```{r fortnight_lts,fig.height=8}
solmetric <- data$V4
mydygraph(solmetric, "lts") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r ltsnodes` 20-core Haswell nodes that were made available to the HPC user community when Sol was launched on Oct 1, 2016. 
It provides `r ltsnodes*ltscores` compute cores with a total performance of `r ltsnodes*ltscores*ltsperf/1000` TFLOPs, `r sprintf("%d",lts)` SUs daily and `r sprintf("%d",ltsnodes*ltscores*superyear)` SUs annually. Four of these nodes have one nVIDIA GTX 1080 card (add --gres=gpu:1 to SLURM commands to request a node with gpu to run gpu workloads)  

Of these `r ltsnodes` nodes, 1 is a condo investment by Dimitrios Vavylonis, Physics. The remaning 8 nodes are Lehigh's investment and are available for purchase annually (total of `r sprintf("%d",8*ltscores*superyear)` SUs annually at $0.01/SU).


Row {data-height=240}
-------------------

### im1080

```{r fortnight_im1080}
solmetric <- data$V6
mydygraph(solmetric,"im1080") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r im1080nodes` 24-core Haswell nodes that were made available to the HPC user community when SOl was launched on Oct 1, 2016. 
It provides `r im1080nodes*im1080cores` compute cores with a total performance of `r im1080nodes*im1080cores*im1080perf/1000` TFLOPs, `r sprintf("%d",im1080)` SUs daily and `r sprintf("%d",im1080nodes*im1080cores*superyear)` SUs annually.

These nodes are condo investment by Wonpil Im, Biological Sciences. Each of these nodes have two nVIDIA GTX 1080 cards that are serviced by a separate partition `im1080-gpu` that requires a minimum of 1 cpu per gpu. The usage reported here is for the combined `im1080` and `im1080-gpu` partition.


Row {data-height=240}
-------------------

### eng

```{r fortnight_eng}
solmetric <- data$V8
mydygraph(solmetric,"eng") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r engnodes` 24-core Haswell nodes that were made available to the HPC user community on March 15, 2017. 
It provides `r engnodes*engcores` compute cores with a total performance of `r engnodes*engcores*engperf/1000` TFLOPs, `r sprintf("%d",eng)` SUs daily and `r sprintf("%d",engnodes*engcores*superyear)` SUs annually.  These nodes are condo investments by: 

- Anand Jagota (Chemical Engineering - 1 node)
- Brian Chen (Computer Science and Engineering - 1 node)
- Ed Webb and Alp Oztekin (Mechanical Engineering  - 6 nodes )

Each of these nodes have one nVIDIA GTX 1080 cards that are serviced by a separate partition `eng-gpu` that requires a minimum of 1 cpu per gpu. Four of these nodes have two GTX cards (add --gres=gpu:2 to SLURM commands to request these nodes). The usage reported here is for the combined `eng` and `eng-gpu` partition. 


Row {data-height=240}
-------------------

### engc

```{r fornight_engc}
solmetric <- data$V10
mydygraph(solmetric,"engc") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r engcnodes` 24-core Broadwell nodes, 13 of which were made available to the HPC user community on May 1, 2017 and 1 on December 1, 2018. 
It provides `r engcnodes*engccores` compute cores with a total performance of `r engcnodes*engccores*engcperf/1000` TFLOPs, `r sprintf("%d",engc)` SUs daily and `r sprintf("%d",engcnodes*engccores*superyear)` SUs annually.

Of these nodes, 13 are condo investments by Srinivas Rangarajan and Jeetain Mittal (Chemical Engineering) and 1 by Paolo Bocchini (Civil and Environmental Engineering)

Row {data-height=240}
-------------------

### himem

```{r fornight_himem}
solmetric <- data$V14
mydygraph(solmetric,"himem") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r himemnodes` 16-core Haswell node that were made available to the HPC user community on Nov 15, 2017. 
It provides `r himemnodes*himemcores` compute cores with a total performance of `r himemnodes*himemcores*himemperf/1000` TFLOPs, `r sprintf("%d",himem)` SUs daily and `r sprintf("%d",himemnodes*himemcores*superyear)` SUs annually.

This node is a condo investment by Seth Richards-Shubik (Economics) that provides upto 512GB RAM and should be used for workloads that require more than 192GB RAM.



Row {data-height=240}
-------------------



### enge

```{r fornight_enge}
solmetric <- data$V16
mydygraph(solmetric,"enge") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r engenodes` 36-core Skylake nodes, 7 were made available to the HPC user community on April 2, 2018, and 1 on April 1, 2019.
It provides `r engenodes*engecores` compute cores with a total performance of `r engenodes*engecores*engeperf/1000` TFLOPs, `r sprintf("%d",enge)` SUs daily and `r sprintf("%d",engenodes*engecores*superyear)` SUs annually.

These nodes are a condo investment by Ganesh Balasubramanian and Hannah Dailey (Mechanical Engineering). `r engecnodes` 36-core Skylake nodes, a condo investmnet by Lisa Fredin (Chemistry) belonged to this partition between November 12, 2018 and May 31, 2020.


Row {data-height=240}
-------------------



### engi

```{r fornight_engi}
solmetric <- data$V18
mydygraph(solmetric,"engi") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r enginodes` 36-core Skylake nodes made available to the HPC user community on August 31, 2018.
It provides `r enginodes*engicores` compute cores with a total performance of `r enginodes*engicores*engiperf/1000` TFLOPs, `r sprintf("%d",engi)` SUs daily and `r sprintf("%d",enginodes*engicores*superyear)` SUs annually.

These nodes are a condo investment by the Department of Industrial and Systems Engineering.


Row {data-height=240}
-------------------

### im2080

```{r fortnight_im2080}
solmetric <- data$V20
mydygraph(solmetric,"im2080") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r im2080nodes` 36-core Skylake nodes that were made available to the HPC user community on Jan 2, 2019. 
It provides `r im2080nodes*im2080cores` compute cores with a total performance of `r im2080nodes*im2080cores*im2080perf/1000` TFLOPs, `r sprintf("%d",im2080)` SUs daily and `r sprintf("%d",im2080nodes*im2080cores*superyear)` SUs annually.

These nodes are condo investment by Wonpil Im, Biological Sciences. Each of these nodes have four nVIDIA RTX 2080 TI cards that are serviced by a separate partition `im2080-gpu` that requires a minimum of 1 cpu per gpu. The usage reported here is for the combined `im2080` and `im2080-gpu` partition.


Row {data-height=240}
-------------------

### chem

```{r fortnight_chem}
solmetric <- data$V22
mydygraph(solmetric,"chem") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r engecnodes` 36-core Skylake and `r chemnodes` 36-core Cascade Lake nodes made available to the HPC user community on June 1, 2020.
It provides `r (engecnodes+chemnodes)*engecores` compute cores with a total performance of `r (engecnodes*engecores*engeperf+chemnodes*chemcores*chemperf)/1000` TFLOPs, `r sprintf("%d",chem)` SUs and `r sprintf("%d", (engecnodes*engecores+chemnodes*chemcores)*superyear)` SUs.

These nodes are a condo investment by  Lisa Fredin, Chemistry. The Skylake nodes were part of the enge partition between 2 Nov, 2018 and 31 May 2020.  


Row {data-height=240}
-------------------

### health

```{r fortnight_health}
solmetric <- data$V24
mydygraph(solmetric,"health") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r healthnodes` 36-core Cascade Lake nodes made available to the HPC user community on August 1, 2020.
It provides `r healthnodes*healthcores` compute cores with a total performance of `r (healthnodes*healthcores*healthperf)/1000` TFLOPs, `r sprintf("%d",health)` SUs daily and `r sprintf("%d", (healthnodes*healthcores)*superyear)` SUs annually.

Row {data-height=240}
-------------------

### hawkcpu

```{r fortnight_hawkcpu}
solmetric <- data$V26
mydygraph(solmetric,"hawkcpu") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r hawkcpunodes` 52-core Cascade Lake nodes from the Hawk Cluster. These were made available to the HPC user community in user friendly mode on December 7, 2020 and in production on February 1, 2021.
It provides `r hawkcpunodes*hawkcpucores` compute cores with a total performance of `r (hawkcpunodes*hawkcpucores*hawkcpuperf)/1000` TFLOPs, `r sprintf("%d",hawkcpunodes*hawkcpucores*24)` SUs daily and `r sprintf("%d", (hawkcpunodes*hawkcpucores)*superyear)` SUs annually.

Row {data-height=240}
-------------------

### hawkmem

```{r fortnight_hawkmem}
solmetric <- data$V28
mydygraph(solmetric,"hawkmem") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r hawkmemnodes` 52-core Cascade Lake large memory nodes from the Hawk Cluster. These were made available to the HPC user community in user friendly mode on December 7, 2020 and in production on February 1, 2021.
It provides `r hawkmemnodes*hawkcpucores` compute cores with a total performance of `r (hawkmemnodes*hawkcpucores*hawkcpuperf)/1000` TFLOPs, `r sprintf("%d",hawkmemnodes*hawkcpucores*24)` SUs daily and `r sprintf("%d", (hawkmemnodes*hawkcpucores)*superyear)` SUs annually.

Row {data-height=240}
-------------------

### hawkgpu

```{r fortnight_hawkgpu}
solmetric <- data$V30
mydygraph(solmetric,"hawkgpu") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r hawkgpunodes` 48-core Cascade Lake GPU enabled nodes from the Hawk Cluster. These were made available to the HPC user community in user friendly mode on December 7, 2020 and in production on February 1, 2021.
It provides `r hawkgpunodes*hawkgpucores` compute cores with a total performance of `r (hawkgpunodes*hawkgpucores*hawkgpuperf)/1000` TFLOPs, `r sprintf("%d",hawkgpunodes*hawkgpucores*24)` SUs daily and `r sprintf("%d", (hawkgpunodes*hawkgpucores)*superyear)` SUs annually.
Each node provides 8 NVIDIA Tesla T4 GPU each providing a total of `r hawkgpu*16`GB GPU memory, `r sprintf("%d",teslat4cuda)` CUDA cores and perfomance of `r hawkgpuperf` TFLOPs. 

Row {data-height=240}
-------------------

### infolab

```{r fortnight_infolab}
solmetric <- data$V32
mydygraph(solmetric,"infolab") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r infolabnodes` 52-core Cascade Lake nodes that were made available to the HPC user community on January 1, 2021.
It provides `r infolabnodes*hawkcpucores` compute cores with a total performance of `r (infolabnodes*hawkcpucores*hawkcpuperf)/1000` TFLOPs, `r sprintf("%d",infolabnodes*hawkcpucores*24)` SUs daily and `r sprintf("%d", (infolabnodes*hawkcpucores)*superyear)` SUs annually.

These nodes are condo investments by Brian Chen, Computer Science and Engineering.

Row {data-height=240}
-------------------

### pisces

```{r fortnight_pisces}
solmetric <- data$V34
mydygraph(solmetric,"pisces") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r piscesnodes` 48-core Cascade Lake node that were made available to the HPC user community on April 5, 2022.
It provides `r piscesnodes*piscescores` compute cores with a total performance of `r (piscesnodes*piscescores*piscescpuperf)/1000` TFLOPs, `r sprintf("%d",piscesnodes*piscescores*24)` SUs daily and `r sprintf("%d", (piscesnodes*piscescores)*superyear)` SUs annually.

This node is a condo investments by Keith Moored, Mechanical Engineering. This node is exclusively for GPU jobs - a maximum of 10 cores can requested per GPU and charging rate of 48SU per SU in addition to 1SU per core. 

Row {data-height=240}
-------------------

### ima40

```{r fortnight_ima40}
solmetric <- data$V36
mydygraph(solmetric,"ima40") %>% dyRangeSelector( dateWindow = dateWindow)
```

### Description

This partition provides `r ima40nodes` 32-core AMD EPYC nodes that were made available to the HPC user community on April 5, 2022.
It provides `r ima40nodes*ima40cores` compute cores with a total performance of `r (ima40nodes*ima40cores*ima40cpuperf)/1000` TFLOPs, `r sprintf("%d",ima40nodes*ima40cores*24)` SUs daily and `r sprintf("%d", (ima40nodes*ima40cores)*superyear)` SUs annually.

These nodes are condo investments by Wonpil Im, Biological Sciences. These nodes are exclusive for GPU jobs - a maximum of 4 cores can requested per GPU and charging rate of 24SU per SU in addition to 1SU per core. 


This Month
=========================================================================

Row
-----------------------------------------------------------------------


```{r thismonth_setup}
users <- thismonth %>%
  group_by(Name) %>%
  summarize(Total=sum(as.double(Total)))
pis <- thismonth %>%
  group_by(PI) %>%
  summarize(Total=sum(as.double(Total)),Jobs=sum(as.double(TotalJ)))
pidept <- thismonth %>%
  group_by(PIDept) %>%
  summarize(Total=sum(as.double(Total)))
dept <- thismonth %>%
  group_by(Department) %>%
  summarize(Total=sum(as.double(Total)))
forttotal <- sum(pis$Total)
fortavail <- all*days_sofar[[1]]
fortusage <- round(forttotal/fortavail*100)
fortjobs <- sum(pis$Jobs)
```

### Active Users

```{r thismonth_users}
valueBox(n_distinct(users$Name), icon = "fa-users")
```

### Active PIs

```{r thismonth_pis}
valueBox(n_distinct(pis$PI), icon = "fa-user-md")
```

### PI Departments

```{r thismonth_pidept}
valueBox(n_distinct(pidept$PIDept), icon = "fa-building")
```

### Users Major/Department

```{r thismonth_userdept}
valueBox(n_distinct(dept$Department), icon = "fa-university")
```

### Jobs Run

```{r thismonth_josbrun}
valueBox(fortjobs, icon = "fa-desktop")
```

### % of SUs consumed

```{r thismonth_sus}
gauge(fortusage, min = 0, max = 100, symbol = '%', gaugeSectors(
success = c(71, 100), warning = c(50, 70), danger = c(0, 49)
))
```

Row {.tabset}
--------------------------------

### Top 10 Users by SUs consumed

```{r thismonth_usersus}
thismonth %>% topuserstotal 
```


### Top 10 Users by Jobs 

```{r thismonth_userjobs}
thismonth %>% topusersjobs
```


Row {.tabset data-height=400}
-----------------------------------------------------------------------


### Sol Usage

```{r thismonth_solusage_setup}
# create time series for dygraphs
if ( mday(today()) < 2 ) {
  dataslice <- data %>% filter(as.Date(V1) >= as.Date(floor_date(currentDate - 2,"month")))
} else {
  dataslice <- data %>% filter(as.Date(V1) >= as.Date(floor_date(currentDate,"month")))
} 
dayslice <- length(dataslice$V1)
d1 <- seq(as.POSIXct(dataslice[1,1]), by = "days", length = dayslice)

mydygraph(dataslice$V2, "Total")
```

### lts

```{r thismonth_lts,fig.height=8}
mydygraph(dataslice$V4, "lts")
```


### im1080

```{r thismonth_im1080}
mydygraph(dataslice$V6, "im1080")
```


### eng

```{r thismonth_eng}
mydygraph(dataslice$V8, "eng")
```


### engc

```{r thismonth_engc}
mydygraph(dataslice$V10, "engc")
```


### himem

```{r thismonth_himem}
mydygraph(dataslice$V14, "himem")
```


### enge

```{r thismonth_enge}
mydygraph(dataslice$V16, "enge")
```

### engi

```{r thismonth_engi}
mydygraph(dataslice$V18, "engi")
```

### im2080

```{r thismonth_im2080}
mydygraph(dataslice$V20, "im2080")
```

### chem

```{r thismonth_chem}
mydygraph(dataslice$V22, "chem")
```

### health

```{r thismonth_health}
mydygraph(dataslice$V24, "health")
```

### hawkcpu

```{r thismonth_hawkcpu}
mydygraph(dataslice$V26, "hawkcpu")
```

### hawkmem

```{r thismonth_hawkmem}
mydygraph(dataslice$V28, "hawkmem")
```

### hawkgpu

```{r thismonth_hawkgpu}
mydygraph(dataslice$V30, "hawkgpu")
```

### infolab

```{r thismonth_infolab}
mydygraph(dataslice$V32, "infolab")
```

### pisces

```{r thismonth_pisces}
mydygraph(dataslice$V34, "pisces")
```

### ima40

```{r thismonth_ima40}
mydygraph(dataslice$V36, "ima40")
```

Row
----------------------------------------------------------------------

### Usage Summary


```{r thismonth_plot_usage}
tribble(
  ~Type,~Value,
  "Used",forttotal,
  "Unused",fortavail-forttotal) %>%
  plot_ly(labels = ~Type, values = ~Value, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)

```

### PI

```{r thismonth_plot_pi}
plot_ly(pis, labels = ~PI, values = ~Total, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```


### PI's Department

```{r thismonth_plot_pidept}
plot_ly(pidept, labels = ~PIDept, values = ~Total, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```


### Department/Major

```{r thismonth_plot_userdept}
plot_ly(dept, labels = ~Department, values = ~Total, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```


Row 
----------------------------------------------------------------------

```{r thismonth_plot_setup}
p <- thismonth %>% 
  summarize(Serial=sum(as.double(Serial)),
    Single=sum(as.double(Single)),
    Multi=sum(as.double(Multi)),
    Total=sum(as.double(Total)),
    SerialJ=sum(as.double(SerialJ)),
    SingleJ=sum(as.double(SingleJ)),
    MultiJ=sum(as.double(MultiJ)),
    TotalJ=sum(as.double(TotalJ)))
pp <- tribble(
     ~Type, ~SU, ~Jobs,
     "Serial", p$Serial, p$SerialJ,
     "Multi-core", p$Single, p$SingleJ,
     "Multi-node", p$Multi, p$MultiJ )
pq <- tribble(
      ~Partition, ~SU,
      "lts", sum(dataslice$V4),
      "im1080",sum(dataslice$V6),
      "eng",sum(dataslice$V8),
      "engc",sum(dataslice$V10),
      "himem",sum(dataslice$V14),
      "enge",sum(dataslice$V16),
      "engi",sum(dataslice$V18),
      "im2080",sum(dataslice$V20),
      "chem",sum(dataslice$V22),
      "health",sum(dataslice$V24),
      "hawkcpu",sum(dataslice$V26),
      "hawkmem",sum(dataslice$V28),
      "hawkgpu",sum(dataslice$V30),
      "infolab",sum(dataslice$V32),
      "pisces",sum(dataslice$V34),
      "ima40",sum(dataslice$V36),
      "all-cpu",sum(dataslice$V12) )
```

### SUs Consumed by Partition

```{r thismonth_plot_su_part}
plot_ly(pq, labels = ~Partition, values = ~SU, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### SUs Consumed by Job Types

```{r thismonth_plot_su_jobtype}
plot_ly(pp, labels = ~Type, values = ~SU, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Number of Jobs by Type

```{r thismonth_plot_num_jobtype}
plot_ly(pp, labels = ~Type, values = ~Jobs, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```


Row 
----------------------------------------------------------------------

```{r thismonth_plot_pi_setup}
p <- thismonth %>% 
  group_by(PI) %>% 
  summarize(Serial=sum(as.double(Serial)),
    Single=sum(as.double(Single)),
    Multi=sum(as.double(Multi)),
    Total=sum(as.double(Total)),
    SerialJ=sum(as.double(SerialJ)),
    SingleJ=sum(as.double(SingleJ)),
    MultiJ=sum(as.double(MultiJ)),
    TotalJ=sum(as.double(TotalJ)))
``` 


### Total Jobs Run 

```{r thismonth_plot_pi_total_jobs}
plot_ly(p, labels = ~PI, values = ~TotalJ, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Serial Jobs

```{r thismonth_plot_pi_serial_jobs}
plot_ly(p, labels = ~PI, values = ~SerialJ, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Multi-core Jobs

```{r thismonth_plot_pi_smp_jobs}
plot_ly(p, labels = ~PI, values = ~SingleJ, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Multi-node Jobs

```{r thismonth_plot_pi_dmp_jobs}
plot_ly(p, labels = ~PI, values = ~MultiJ, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

Row
------------------------------------------------------

### Total SUs Consumed

```{r thismonth_plot_pi_sus_total}
plot_ly(p, labels = ~PI, values = ~Total, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Serial Jobs

```{r thismonth_plot_pi_sus_serial}
plot_ly(p, labels = ~PI, values = ~Serial, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Multi-core Jobs

```{r thismonth_plot_pi_sus_smp}
plot_ly(p, labels = ~PI, values = ~Single, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Multi-node Jobs

```{r thismonth_plot_pi_sus_dmp}
plot_ly(p, labels = ~PI, values = ~Multi, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```


Previous Month
=========================================================================

Row
-----------------------------------------------------------------------


```{r prevmonth_setup}
users <- prevmonth %>%
  group_by(Name) %>%
  summarize(Total=sum(as.double(Total)))
pis <- prevmonth %>%
  group_by(PI) %>%
  summarize(Total=sum(as.double(Total)),Jobs=sum(as.double(TotalJ)))
pidept <- prevmonth %>%
  group_by(PIDept) %>%
  summarize(Total=sum(as.double(Total)))
dept <- prevmonth %>%
  group_by(Department) %>%
  summarize(Total=sum(as.double(Total)))
forttotal <- sum(pis$Total)
fortavail <- all*days_prev_month[[1]]
fortusage <- round(forttotal/fortavail*100)
fortjobs <- sum(pis$Jobs)
```

### Active Users

```{r prevmonth_users}
valueBox(n_distinct(users$Name), icon = "fa-users")
```

### Active PIs

```{r prevmonth_pis}
valueBox(n_distinct(pis$PI), icon = "fa-user-md")
```

### PI Departments

```{r prevmonth_pidept}
valueBox(n_distinct(pidept$PIDept), icon = "fa-building")
```

### Users Major/Department

```{r prevmonth_userdept}
valueBox(n_distinct(dept$Department), icon = "fa-university")
```

### Jobs Run

```{r prevmonth_josbrun}
valueBox(fortjobs, icon = "fa-desktop")
```

### % of SUs consumed

```{r prevmonth_sus}
gauge(fortusage, min = 0, max = 100, symbol = '%', gaugeSectors(
  success = c(71, 100), warning = c(50, 70), danger = c(0, 49)
))
```

Row {.tabset}
--------------------------------

### Top 10 Users by SUs consumed

```{r prevmonth_usersus}
prevmonth %>% topuserstotal 
```


### Top 10 Users by Jobs 

```{r prevmonth_userjobs}
prevmonth %>% topusersjobs
```


Row {.tabset data-height=400}
-----------------------------------------------------------------------


### Sol Usage

```{r prevmonth_solusage_setup}
# create time series for dygraphs
if ( mday(today()) < 2 ) {
  dataslice <- data %>% filter(as.Date(V1) >= as.Date(floor_date(currentDate - 2,"month")))
} else {
  dataslice <- data %>% filter(as.Date(V1) >= floor_date(currentDate - days(day(currentDate)),"month") & as.Date(V1) < as.Date(cut(currentDate,"month")))
} 
dayslice <- length(dataslice$V1)
d1 <- seq(as.POSIXct(dataslice[1,1]), by = "days", length = dayslice)

mydygraph(dataslice$V2, "Total")
```

### lts

```{r prevmonth_lts,fig.height=8}
mydygraph(dataslice$V4, "lts")
```


### im1080

```{r prevmonth_im1080}
mydygraph(dataslice$V6, "im1080")
```


### eng

```{r prevmonth_eng}
mydygraph(dataslice$V8, "eng")
```


### engc

```{r prevmonth_engc}
mydygraph(dataslice$V10, "engc")
```


### himem

```{r prevmonth_himem}
mydygraph(dataslice$V14, "himem")
```


### enge

```{r prevmonth_enge}
mydygraph(dataslice$V16, "enge")
```

### engi

```{r prevmonth_engi}
mydygraph(dataslice$V18, "engi")
```

### im2080

```{r prevmonth_im2080}
mydygraph(dataslice$V20, "im2080")
```

### chem

```{r prevmonth_chem}
mydygraph(dataslice$V22, "chem")
```

### health

```{r prevmonth_health}
mydygraph(dataslice$V24, "health")
```

### hawkcpu

```{r prevmonth_hawkcpu}
mydygraph(dataslice$V26, "hawkcpu")
```

### hawkmem

```{r prevmonth_hawkmem}
mydygraph(dataslice$V28, "hawkmem")
```

### hawkgpu

```{r prevmonth_hawkgpu}
mydygraph(dataslice$V30, "hawkgpu")
```

### infolab

```{r prevmonth_infolab}
mydygraph(dataslice$V32, "infolab")
```

### pisces

```{r prevmonth_pisces}
mydygraph(dataslice$V34, "pisces")
```

### ima40

```{r prevmonth_ima40}
mydygraph(dataslice$V36, "ima40")
```


Row
----------------------------------------------------------------------

### Usage Summary


```{r prevmonth_plot_usage}
tribble(
  ~Type,~Value,
  "Used",forttotal,
  "Unused",fortavail-forttotal) %>%
  plot_ly(labels = ~Type, values = ~Value, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)

```

### PI

```{r prevmonth_plot_pi}
plot_ly(pis, labels = ~PI, values = ~Total, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```


### PI's Department

```{r prevmonth_plot_pidept}
plot_ly(pidept, labels = ~PIDept, values = ~Total, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```


### Department/Major

```{r prevmonth_plot_userdept}
plot_ly(dept, labels = ~Department, values = ~Total, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```


Row 
----------------------------------------------------------------------

```{r prevmonth_plot_setup}
p <- prevmonth %>% 
  summarize(Serial=sum(as.double(Serial)),
    Single=sum(as.double(Single)),
    Multi=sum(as.double(Multi)),
    Total=sum(as.double(Total)),
    SerialJ=sum(as.double(SerialJ)),
    SingleJ=sum(as.double(SingleJ)),
    MultiJ=sum(as.double(MultiJ)),
    TotalJ=sum(as.double(TotalJ)))
pp <- tribble(
     ~Type, ~SU, ~Jobs,
     "Serial", p$Serial, p$SerialJ,
     "Multi-core", p$Single, p$SingleJ,
     "Multi-node", p$Multi, p$MultiJ )
pq <- tribble(
      ~Partition, ~SU,
      "lts", sum(dataslice$V4),
      "im1080",sum(dataslice$V6),
      "eng",sum(dataslice$V8),
      "engc",sum(dataslice$V10),
      "himem",sum(dataslice$V14),
      "enge",sum(dataslice$V16),
      "engi",sum(dataslice$V18),
      "im2080",sum(dataslice$V20),
      "chem",sum(dataslice$V22),
      "health",sum(dataslice$V24),
      "hawkcpu",sum(dataslice$V26),
      "hawkmem",sum(dataslice$V28),
      "hawkgpu",sum(dataslice$V30),
      "infolab",sum(dataslice$V32),
      "pisces",sum(dataslice$V34),
      "ima40",sum(dataslice$V36),
      "all-cpu",sum(dataslice$V12) )
```

### SUs Consumed by Partition

```{r prevmonth_plot_su_part}
plot_ly(pq, labels = ~Partition, values = ~SU, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### SUs Consumed by Job Types

```{r prevmonth_plot_su_jobtype}
plot_ly(pp, labels = ~Type, values = ~SU, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Number of Jobs by Type

```{r prevmonth_plot_num_jobtype}
plot_ly(pp, labels = ~Type, values = ~Jobs, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```


Row 
----------------------------------------------------------------------

```{r prevmonth_plot_pi_setup}
p <- prevmonth %>% 
  group_by(PI) %>% 
  summarize(Serial=sum(as.double(Serial)),
    Single=sum(as.double(Single)),
    Multi=sum(as.double(Multi)),
    Total=sum(as.double(Total)),
    SerialJ=sum(as.double(SerialJ)),
    SingleJ=sum(as.double(SingleJ)),
    MultiJ=sum(as.double(MultiJ)),
    TotalJ=sum(as.double(TotalJ)))
``` 


### Total Jobs Run 

```{r prevmonth_plot_pi_total_jobs}
plot_ly(p, labels = ~PI, values = ~TotalJ, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Serial Jobs

```{r prevmonth_plot_pi_serial_jobs}
plot_ly(p, labels = ~PI, values = ~SerialJ, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Multi-core Jobs

```{r prevmonth_plot_pi_smp_jobs}
plot_ly(p, labels = ~PI, values = ~SingleJ, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Multi-node Jobs

```{r prevmonth_plot_pi_dmp_jobs}
plot_ly(p, labels = ~PI, values = ~MultiJ, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

Row
------------------------------------------------------

### Total SUs Consumed

```{r prevmonth_plot_pi_sus_total}
plot_ly(p, labels = ~PI, values = ~Total, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Serial Jobs

```{r prevmonth_plot_pi_sus_serial}
plot_ly(p, labels = ~PI, values = ~Serial, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Multi-core Jobs

```{r prevmonth_plot_pi_sus_smp}
plot_ly(p, labels = ~PI, values = ~Single, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```

### Multi-node Jobs

```{r prevmonth_plot_pi_sus_dmp}
plot_ly(p, labels = ~PI, values = ~Multi, type = 'pie', textposition = 'inside', textinfo = 'label', showlegend = F)
```


Summary {data-navmenu="Annual Reports"}
====================================================================

Row
--------------------------------------------------------------------

```{r annualrep_monthly_setup}
compress <- function(tx) {
  tx <- as.numeric(gsub("\\,", "", tx))
  int <- c(1e-2, 1, 1e3, 1e6, 1e9, 1e12)
  div <- findInterval(tx, int)
  paste(round( tx/int[div], 2), c(1e-2,"", "K","M","B","T")[div] )
}

monthlyreport  <- monthly %>% 
  group_by(Month) %>%	
  summarize(Total=round(sum(as.double(Total)),2),User=n_distinct(Name),Jobs=round(sum(as.double(TotalJ))))

pireport <- monthly %>% 
  group_by(PI) %>% 
  summarize(Total=round(sum(as.double(Total)),2),User=n_distinct(Name),Jobs=round(sum(as.double(TotalJ)))) 

pideptreport <- monthly %>% 
  group_by(PIDept) %>% 
  summarize(Total=round(sum(as.double(Total)),2),User=n_distinct(Name),Jobs=round(sum(as.double(TotalJ))))

deptreport <- monthly %>% 
  group_by(Department) %>% 
  summarize(Total=round(sum(as.double(Total)),2),User=n_distinct(Name),Jobs=round(sum(as.double(TotalJ))))

userusage <- monthly %>% 
  group_by(Status) %>% 
  summarize(Total=round(sum(as.double(Total)),2),User=n_distinct(Name),Jobs=round(sum(as.double(TotalJ))))

users <- monthly %>%
  group_by(Name) %>%
  summarize(Total=sum(as.double(Total)))

pis <- monthly %>%
  group_by(PI) %>%
  summarize(Total=sum(as.double(Total)),Jobs=sum(as.double(TotalJ)))

pidept <- monthly %>%
  group_by(PIDept) %>%
  summarize(Total=sum(as.double(Total)))

dept <- monthly %>%
  group_by(Department) %>%
  summarize(Total=sum(as.double(Total)))

forttotal <- sum(pis$Total)
fortusage <- round(forttotal/(sum(aysu))*100)
fortjobs <- sum(pis$Jobs)
```

### Active Users

```{r annualrep_users}
valueBox(n_distinct(users$Name), icon = "fa-users")
```

### Active PIs

```{r annualrep_pis}
valueBox(n_distinct(pis$PI), icon = "fa-user-md")
```

### PI Departments

```{r annualrep_pidept}
valueBox(n_distinct(pidept$PIDept), icon = "fa-building")
```

### Users Major/Department

```{r annualrep_userdept}
valueBox(n_distinct(dept$Department), icon = "fa-university")
```

### SUs consumed

	```{r annualrep_susconsumed}
valueBox(compress(forttotal), icon = "fa-desktop")
```


### Jobs

```{r annualrep_jobs}
valueBox(compress(fortjobs), icon = "fa-desktop")
```

### % of SUs consumed

```{r annualrep_sus}
gauge(fortusage, min = 0, max = 100, symbol = '%', gaugeSectors(
success = c(71, 100), warning = c(50, 70), danger = c(0, 49)
))
```

	
Row {.tabset}
--------------------------------

### Top Users 

```{r annualrep_users_sus-jobs}
monthly %>% group_by(Name,Major=Department,PI,Department=PIDept,Status) %>%
	summarize(SUs=sum(round(as.double(Total))),Jobs=sum(round(as.double(TotalJ)))) %>%
	arrange(desc(SUs),desc(Jobs)) %>% head(25) %>%
	datatable(rownames=FALSE,options=list(dom='t', autoWidth = TRUE))
```

### Top PIs

```{r annualrep_pis_sus-jobs}
monthly %>% group_by(PI,Department=PIDept) %>%
	summarize(SUs=sum(round(as.double(Total))),Jobs=sum(round(as.double(TotalJ)))) %>%
	arrange(desc(SUs),desc(Jobs)) %>% head(25) %>% 
	datatable(rownames=FALSE,options=list(dom = 't', autoWidth = TRUE))
```	

### Top Majors 

```{r annualrep_majors_sus-jobs}
monthly %>% group_by(Major=Department,Status) %>%
	summarize(Users=n_distinct(Name),SUs=sum(round(as.double(Total))),Jobs=sum(round(as.double(TotalJ)))) %>%
	arrange(desc(SUs),desc(Jobs),desc(Users)) %>% head(25) %>%
	datatable(rownames=FALSE,options=list(dom='t', autoWidth = TRUE))
```

### Top Departments

```{r annualrep_pidept_sus-jobs}
monthly %>% group_by(Department=PIDept) %>%
	summarize(PI=n_distinct(PI),Users=n_distinct(Name),SUs=sum(round(as.double(Total))),Jobs=sum(round(as.double(TotalJ)))) %>%
	arrange(desc(SUs),desc(Jobs),desc(PI),desc(Users)) %>% head(25) %>% 
	datatable(rownames=FALSE,options=list(dom = 't', autoWidth = TRUE))
```	

### Total Usage

	
```{r annualrep_summary_setup}
aymonth<- seq(as.Date("2016-10-01"), as.Date("2022-09-30"), by = "month")
AYSU <- tibble(Month=aymonth,Available=aysu) %>% filter(Month <= today())
aydaily <- AYSU %>% mutate(Date = ymd(Month)) %>% group_by(Date) %>% expand(Date = seq(floor_date(Date, unit = "month"), today(), by="day"), Available)

#length(aysu)
monthly_summary <- daily %>%
  group_by(Month=floor_date(as.Date(Day),"month")) %>%
  summarize(Total=sum(as.double(Total)),
	    Jobs=sum(as.double(TotalJ))) %>%
  drop_na()
##monthly$Available <- aysu
monthly_summary <- left_join(monthly_summary,AYSU)
dateWindow = c(as.Date("2016-09-01") , today() + 31 )

annual_summary <- daily %>%
	group_by(Year=floor_date(as.Date(Day),"year")) %>%
	summarize(SUs=sum(as.double(Total)),Jobs=sum(as.double(TotalJ)))
pis <- daily %>%
	group_by(Year=floor_date(as.Date(Day),"year"),PI) %>%
	summarize(PI=n()) %>%
	tally(n = 'PI')
pidept <- daily %>%
	group_by(Year=floor_date(as.Date(Day),"year"),PIDept) %>%
	summarize(PIDept=n()) %>%
	tally(n = 'PIDept')
users <- daily %>%
	group_by(Year=floor_date(as.Date(Day),"year"),Name) %>%
	summarize(Users=n()) %>%
	tally(n = 'Users')
dept <- daily %>%
	group_by(Year=floor_date(as.Date(Day),"year"),Department) %>%
	summarize(Department=n()) %>%
	tally(n = 'Department')
annual_summary <- left_join(left_join(left_join(left_join(annual_summary,pis),users),pidept),dept)

pideptusage <- daily %>%
	group_by(PIDept) %>%
	summarize(Total=sum(as.double(Total)),Jobs=sum(as.double(TotalJ)),User=sum(n_distinct(Name)))
userdeptusage <- daily %>%
	group_by(Department) %>%
	summarize(Total=sum(as.double(Total)),Jobs=sum(as.double(TotalJ)),User=sum(n_distinct(Name)))
```
	
```{r annualrep_monthly_usage}
dygraph( xts(cbind(monthly_summary$Total,monthly_summary$Available), order.by = monthly_summary$Month)) %>%
  dySeries("V1", label = "Consumed", color = "blue", stepPlot = TRUE, fillGraph = TRUE) %>%
  dySeries("V2", label = "Total Available", color = "green", stepPlot = TRUE, fillGraph = TRUE) %>%
  dyAxis("y", label = "CPU Hours per Month") %>%
  dyOptions(stackedGraph = FALSE, axisLineWidth = 1.5, fillGraph = TRUE, drawGrid = FALSE, labelsKMB = TRUE) %>%
  dyHighlight(highlightSeriesOpts = list(strokeWidth = 3)) %>%
  dyRoller(rollPeriod = 1) %>%
  dyEvent("2016-10-01", "Sol launched with 34 nodes, 760 cores", labelLoc = "top") %>% 
  dyEvent("2017-01-19", "34 nodes, 760 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-03-15", "42 nodes, 972 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-05-01", "55 nodes, 1284 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-11-15", "56 nodes, 1300 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-12-01", "56 nodes, 1300 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-04-02", "63 nodes, 1552 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-08-31", "65 nodes, 1624 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-11-12", "66 nodes, 1648 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-12-01", "68 nodes, 1720 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2019-01-02", "80 nodes, 2152 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2019-04-01", "81 nodes, 2188 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-05-31", "85 nodes, 2332 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-08-01", "87 nodes, 2404 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-11-12", "Hawk: User Friendly", labelLoc = "top") %>%
  dyEvent("2021-02-01", "Hawk in Production", labelLoc = "top") %>%
  dyEvent("2022-04-05", "127 nodes, 4404 cores, 181 GPUs", labelLoc = "top") %>%
  dyRangeSelector( dateWindow = dateWindow)
```

### Number of Jobs
	
```{r annualrep_monthly_jobs}
dygraph( xts(monthly_summary$Jobs, order.by = monthly_summary$Month)) %>%
  dySeries("V1", label = "Jobs", color = "blue", stepPlot = TRUE, fillGraph = TRUE) %>%
  dyAxis("y", label = "Jobs per Month") %>%
  dyOptions(stackedGraph = FALSE, axisLineWidth = 1.5, fillGraph = TRUE, drawGrid = FALSE, labelsKMB = TRUE) %>%
  dyHighlight(highlightSeriesOpts = list(strokeWidth = 3)) %>%
  dyRoller(rollPeriod = 1) %>%
  dyEvent("2016-10-01", "Sol launched with 34 nodes, 760 cores", labelLoc = "top") %>% 
  dyEvent("2017-01-19", "34 nodes, 760 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-03-15", "42 nodes, 972 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-05-01", "55 nodes, 1284 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-11-15", "56 nodes, 1300 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-12-01", "56 nodes, 1300 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-04-02", "63 nodes, 1552 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-08-31", "65 nodes, 1624 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-11-12", "66 nodes, 1648 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-12-01", "68 nodes, 1720 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2019-01-02", "80 nodes, 2152 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2019-04-01", "81 nodes, 2188 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-05-31", "85 nodes, 2332 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-08-01", "87 nodes, 2404 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-11-12", "Hawk: User Friendly", labelLoc = "top") %>%
  dyEvent("2021-02-01", "Hawk in Production", labelLoc = "top") %>%
  dyEvent("2022-04-05", "127 nodes, 4404 cores, 181 GPUs", labelLoc = "top") %>%
  dyRangeSelector( dateWindow = dateWindow)
```

### Usage by Job Type

```{r annualrep_sus_type}
sujobs <- daily %>%
  group_by(Month=floor_date(as.Date(Day),"month")) %>%
  summarize(Serial=sum(as.double(Serial)),SMP=sum(as.double(Single)),Multi=sum(as.double(Multi)),
            SerialJ=sum(as.double(SerialJ)),SMPJ=sum(as.double(SingleJ)),MultiJ=sum(as.double(MultiJ))) %>%
  drop_na()
dygraph(xts(cbind(sujobs$Serial,sujobs$SMP,sujobs$Multi), order.by = sujobs$Month )) %>%
  dySeries("V1", label = "Serial", color = "blue", stepPlot = TRUE, fillGraph = TRUE) %>%
  dySeries("V2", label = "Single", color = "green", stepPlot = TRUE, fillGraph = TRUE) %>%
  dySeries("V3", label = "Multi", color = "orange", stepPlot = TRUE, fillGraph = TRUE) %>%
  dyOptions(stackedGraph = TRUE,axisLineWidth = 1.5, fillGraph = TRUE, drawGrid = FALSE, labelsKMB = TRUE ) %>%
  dyAxis("y", label = "CPU Hours per Month") %>%
  dyLegend(show = "follow" ) %>%
  dyHighlight(highlightSeriesOpts = list(strokeWidth = 3)) %>%
  dyRangeSelector( dateWindow = dateWindow)
```

### Number of Jobs by Type

```{r annualrep_jobs_type}
dygraph(xts(cbind(sujobs$SerialJ,sujobs$SMPJ,sujobs$MultiJ), order.by = sujobs$Month )) %>%
  dySeries("V1", label = "Serial", color = "blue", stepPlot = TRUE, fillGraph = TRUE) %>%
  dySeries("V2", label = "Single", color = "green", stepPlot = TRUE, fillGraph = TRUE) %>%
  dySeries("V3", label = "Multi", color = "orange", stepPlot = TRUE, fillGraph = TRUE) %>%
  dyOptions(stackedGraph = TRUE,axisLineWidth = 1.5, fillGraph = TRUE, drawGrid = FALSE, labelsKMB = TRUE ) %>%
  dyAxis("y", label = "CPU Hours per Month") %>%
  dyLegend(show = "follow" ) %>%
  dyHighlight(highlightSeriesOpts = list(strokeWidth = 3)) %>%
  dyRangeSelector( dateWindow = dateWindow)
```

### Power Consumption

```{r annualrep_powerconsump}
dygraph( xts(cbind(monthlypower$Power/1000,monthlypower$Energy/1000), order.by = monthlypower$Month)) %>%
  dySeries("V1", label = "Power/kW", color = "blue", stepPlot = TRUE, fillGraph = TRUE) %>%
  dySeries("V2", label = "Energy/MWh", color = "green", stepPlot = TRUE, fillGraph = TRUE) %>%
  dyAxis("y", label = "Average Monthly consumption") %>%
  dyOptions(stackedGraph = FALSE, axisLineWidth = 1.5, fillGraph = TRUE, drawGrid = FALSE, labelsKMB = TRUE) %>%
  dyHighlight(highlightSeriesOpts = list(strokeWidth = 3)) %>%
  dyRoller(rollPeriod = 1) %>%
  dyEvent("2016-10-01", "Sol launched with 34 nodes, 760 cores", labelLoc = "top") %>% 
  dyEvent("2017-01-19", "34 nodes, 760 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-03-15", "42 nodes, 972 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-05-01", "55 nodes, 1284 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-11-15", "56 nodes, 1300 cores, 50 GPUs", labelLoc = "top") %>%
  dyEvent("2017-12-01", "56 nodes, 1300 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-04-02", "63 nodes, 1552 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-08-31", "65 nodes, 1624 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-11-12", "66 nodes, 1648 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2018-12-01", "68 nodes, 1720 cores, 72 GPUs", labelLoc = "top") %>%
  dyEvent("2019-01-02", "80 nodes, 2152 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2019-04-01", "81 nodes, 2188 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-05-31", "85 nodes, 2332 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-08-01", "87 nodes, 2404 cores, 120 GPUs", labelLoc = "top") %>%
  dyEvent("2020-11-12", "Hawk: User Friendly", labelLoc = "top") %>%
  dyEvent("2021-02-01", "Hawk in Production", labelLoc = "top") %>%
  dyRangeSelector( dateWindow =  c(as.Date("2017-06-01") , today() + 31 ))
```

Row {.tabset}
----------------------------------------------------------	

### CPU Hours consumed
	
```{r annualrep_usageperyear}
annual_summary %>%
	plot_ly(x = ~Year, y = ~SUs, type = 'bar', name = "SUs consumed") %>%
	layout(xaxis = list(title = '' ), yaxis = list(title = 'CPU Hours consumed' ))
```


### Number of Jobs
	
```{r annualrep_jobsperyear}
annual_summary %>%
	plot_ly(x = ~Year, y = ~Jobs, type = 'bar', name = "Number of Jobs") %>%
	layout(xaxis = list(title = '' ), yaxis = list(title = 'Number of Jobs' ))
```

	
### Number of PIs
	
```{r annualrep_pisperyear}
annual_summary %>%
	plot_ly(x = ~Year, y = ~PI, type = 'bar', name = "Number of PIs") %>%
	layout(xaxis = list(title = '' ), yaxis = list(title = 'Number of PIs' ))
```

	
### Number of Users
	
```{r annualrep_usersperyear}
annual_summary %>%
	plot_ly(x = ~Year, y = ~Users, type = 'bar', name = "Number of Users") %>%
	layout(xaxis = list(title = '' ), yaxis = list(title = 'Number of Users' ))
```

### Number of Department by PI
	
```{r annualrep_pideptsperyear}
annual_summary %>%
	plot_ly(x = ~Year, y = ~PIDept, type = 'bar', name = "Number of Departments") %>%
	layout(xaxis = list(title = '' ), yaxis = list(title = 'Number of Departments' ))
```

	
### Number of Major/Department by Users
	
```{r annualrep_userdeptsperyear}
annual_summary %>%
	plot_ly(x = ~Year, y = ~Department, type = 'bar', name = "Number of Major/Departments") %>%
	layout(xaxis = list(title = '' ), yaxis = list(title = 'Number of Major/Departments' ))
```

### Usage by User Type
	
```{r annualrep_userstatussus}
users_status <- daily %>% group_by(Status) %>%
	summarize(Total=round(sum(as.double(Total)),2),
	          User=n_distinct(Name),
	          Jobs=round(sum(as.double(TotalJ)))) %>%
	filter(Total > 1)
users_status %>%
	plot_ly(x = ~Total, y = ~Status, type = 'bar', name = "SUs consumed") %>%
	layout(xaxis = list(title = '', type = 'log'),
	   yaxis = list(title = '' ),
	   margin = list(l = 200, r = 20, t = 25, b = 25))
```

### Jobs by User Type
	
```{r annualrep_userstatusjobs}
users_status %>%
	plot_ly(x = ~Jobs, y = ~Status, type = 'bar', name = "Number of Jobs") %>%
	layout(xaxis = list(title = '', type = 'log'),
	   yaxis = list(title = '' ),
	   margin = list(l = 200, r = 20, t = 25, b = 25))
```
	

### Number of Users by Type
	
```{r annualrep_userstatusnum}
users_status %>%
	plot_ly(x = ~User, y = ~Status, type = 'bar', name = "Number of Users") %>%
	layout(xaxis = list(title = '', type = 'log'),
	   yaxis = list(title = '' ),
	   margin = list(l = 200, r = 20, t = 25, b = 25))
```

Row {.tabset data-height=1600}
-------------------------------------------------------------------------

### Usage by PI's Department

```{r annualrep_pideptusage_sus}
plot_ly(pideptusage, x = ~Total, y = ~reorder(PIDept, Total), type = "bar",
	name = "Usage by PI" , orientation = 'h') %>%
	layout(xaxis = list(title = '', type = 'log' ),
	  yaxis = list(title = "" ),
	  margin = list(l = 200, r = 20, t = 25, b = 25))
```

### Jobs by PI's Department


```{r annualrep_pideptusage_jobs}
plot_ly(pideptusage, x = ~Jobs, y = ~reorder(PIDept, Total), type = "bar",
	name = "Jobs by PI" , orientation = 'h') %>%
	layout(xaxis = list(title = '', type = 'log' ),
	  yaxis = list(title = "" ),
	  margin = list(l = 200, r = 20, t = 25, b = 25))
```

### Users by PI's Department


```{r annualrep_pideptusage_users}
plot_ly(pideptusage, x = ~User, y = ~reorder(PIDept, Total), type = "bar",
	name = "Users by PI" , orientation = 'h') %>%
	layout(xaxis = list(title = '', type = 'log' ),
	  yaxis = list(title = "" ),
	  margin = list(l = 200, r = 20, t = 25, b = 25))
```
	
### Usage by Users Major/Department

```{r annualrep_userdeptusage_sus}
plot_ly(userdeptusage, x = ~Total, y = ~reorder(Department, Total), type = "bar",
	name = "Usage by PI" , orientation = 'h') %>%
	layout(xaxis = list(title = '', type = 'log' ),
	  yaxis = list(title = "" ),
	  margin = list(l = 200, r = 20, t = 25, b = 25))
```

### Jobs by  Users Major/Department


```{r annualrep_userdeptusage_jobs}
plot_ly(userdeptusage, x = ~Jobs, y = ~reorder(Department, Total), type = "bar",
	name = "Jobs by PI" , orientation = 'h') %>%
	layout(xaxis = list(title = '', type = 'log' ),
	  yaxis = list(title = "" ),
	  margin = list(l = 200, r = 20, t = 25, b = 25))
```

### Users by  Users Major/Department


```{r annualrep_userdeptusage_users}
plot_ly(userdeptusage, x = ~User, y = ~reorder(Department, Total), type = "bar",
	name = "Users by PI" , orientation = 'h') %>%
	layout(xaxis = list(title = '', type = 'log' ),
	  yaxis = list(title = "" ),
	  margin = list(l = 200, r = 20, t = 25, b = 25))
```

	
Summary {data-navmenu="Job Types"}
===========================================================


Row
-----------------------------------------------------------

### Description

There are three types of jobs that can be run on Sol

*  __Single__: These are jobs that request only one compute core including GPU jobs.
*  __SMP__: These are jobs that request only one node and more than one core. These could be symmetric multi threaded jobs and a bunch of __Single__ jobs run in parallel. These jobs do not utilize more than one node and do not use the infiniband fabric.
* __Multi__: These are jobs that request more than one node. These are jobs are primarily distributed parallel or mpi jobs that make use of the infiniband fabric. These jobs also include __Single__ or __SMP__ jobs that are distributed across the requested nodes and/or compute cores that do not use the infiniband fabric.

The reports for PIs are cummalative since Oct 1, 2016.

 
Row {.tabset}
-----------------------------------------------------------

### SUs Consumed 

```{r summary_sus}
monthly %>%
  group_by(Month) %>%
  summarize(Serial=sum(as.double(Serial)),
    Single=sum(as.double(Single)),
    Multi=sum(as.double(Multi)),
    Total=sum(as.double(Total))) %>%
  plot_ly(x = ~Month, y = ~Serial, type = "bar", name = "Single" ) %>%
    add_trace(y =  ~Single, name = "SMP") %>%
    add_trace(y =  ~Multi, name = "Multi") %>%
    layout(yaxis = list(title = ' ' ), xaxis = list(title = 'Month' ), barmode = 'stack')
```

 
### Number of Jobs

```{r summary_jobs}
monthly %>%
  group_by(Month) %>%
  summarize(SerialJ=sum(as.double(SerialJ)),
    SingleJ=sum(as.double(SingleJ)),
    MultiJ=sum(as.double(MultiJ)),
    TotalJ=sum(as.double(TotalJ))) %>%
  plot_ly(x = ~Month, y = ~SerialJ, type = "bar", name = "Single" ) %>%
    add_trace(y =  ~SingleJ, name = "SMP") %>%
    add_trace(y =  ~MultiJ, name = "Multi") %>%
    layout(yaxis = list(title = ' ' ), xaxis = list(title = 'Month' ), barmode = 'stack')
```

### SUs Consumed by %

```{r summary_sus_percent}
monthly %>%
  group_by(Month) %>%
  summarize(Serial=sum(as.double(Serial)),
    Single=sum(as.double(Single)),
    Multi=sum(as.double(Multi)),
    Total=sum(as.double(Total))) %>%
  mutate(Serial=round(Serial/Total*100,2),Single=round(Single/Total*100,2),Multi=round(Multi/Total*100,2)) %>%
  plot_ly(x = ~Month, y = ~Serial, type = "bar", name = "Single" ) %>%
    add_trace(y =  ~Single, name = "SMP") %>%
    add_trace(y =  ~Multi, name = "Multi") %>%
    layout(yaxis = list(title = ' ' ), xaxis = list(title = 'Month' ), barmode = 'stack')
```

 
### Number of Jobs by %

```{r summary_jobs_percent}
monthly %>%
  group_by(Month) %>%
  summarize(SerialJ=sum(as.double(SerialJ)),
    SingleJ=sum(as.double(SingleJ)),
    MultiJ=sum(as.double(MultiJ)),
    TotalJ=sum(as.double(TotalJ))) %>%
  mutate(SerialJ=round(SerialJ/TotalJ*100,2),SingleJ=round(SingleJ/TotalJ*100,2),MultiJ=round(MultiJ/TotalJ*100,2)) %>%
  plot_ly(x = ~Month, y = ~SerialJ, type = "bar", name = "Single" ) %>%
    add_trace(y =  ~SingleJ, name = "SMP") %>%
    add_trace(y =  ~MultiJ, name = "Multi") %>%
    layout(yaxis = list(title = ' ' ), xaxis = list(title = 'Month' ), barmode = 'stack')
```

Row { data-height=1600}
----------------------------------------------------

### SUs Consumed

```{r summary_sus_pi}
monthly %>%
  group_by(PI) %>%
  summarize(Serial=sum(as.double(Serial)),
    Single=sum(as.double(Single)),
    Multi=sum(as.double(Multi)),
    Total=sum(as.double(Total))) %>%
  plot_ly(x = ~Serial, y = ~reorder(PI,Total), type = "bar", name = "Single",  orientation = 'h' ) %>%
    add_trace(x =  ~Single, name = "SMP") %>%
    add_trace(x =  ~Multi, name = "Multi") %>%
    layout(xaxis = list(title = '', type = 'log' ), yaxis = list(title = '' ), barmode = 'stack', margin = list(l = 200, r = 20, t = 25, b = 25) )
``` 

### SUs Consumed by %

```{r summary_sus_pi_percent}
monthly %>%
  group_by(PI) %>%
  summarize(Serial=sum(as.double(Serial)),
    Single=sum(as.double(Single)),
    Multi=sum(as.double(Multi)),
    Total=sum(as.double(Total))) %>%
  mutate(Serial=round(Serial/Total*100,2),Single=round(Single/Total*100,2),Multi=round(Multi/Total*100,2)) %>%
  plot_ly(x = ~Serial, y = ~reorder(PI,Total), type = "bar", name = "Single",  orientation = 'h' ) %>%
    add_trace(x =  ~Single, name = "SMP") %>%
    add_trace(x =  ~Multi, name = "Multi") %>%
    layout(xaxis = list(title = '' ), yaxis = list(title = '' ), barmode = 'stack', margin = list(l = 200, r = 20, t = 25, b = 25) )
``` 

Row { data-height=1600}
----------------------------------------------------

### Number of Jobs

```{r summary_jobs_pi}
monthly %>%
  group_by(PI) %>%
  summarize(SerialJ=sum(as.double(SerialJ)),
    SingleJ=sum(as.double(SingleJ)),
    MultiJ=sum(as.double(MultiJ)),
    TotalJ=sum(as.double(TotalJ)),Total=sum(as.double(Total))) %>%
  plot_ly(x = ~SerialJ, y = ~reorder(PI,Total), type = "bar", name = "Single",  orientation = 'h' ) %>%
    add_trace(x =  ~SingleJ, name = "SMP") %>%
    add_trace(x =  ~MultiJ, name = "Multi") %>%
    layout(xaxis = list(title = '', type = 'log' ), yaxis = list(title = '' ), barmode = 'stack', margin = list(l = 200, r = 20, t = 25, b = 25) )
``` 

### Number of Jobs by %

```{r summary_jobs_pi_percent}
monthly %>%
  group_by(PI) %>%
  summarize(SerialJ=sum(as.double(SerialJ)),
    SingleJ=sum(as.double(SingleJ)),
    MultiJ=sum(as.double(MultiJ)),
    TotalJ=sum(as.double(TotalJ)),
    Total=sum(as.double(Total))) %>%
  mutate(SerialJ=round(SerialJ/TotalJ*100,2),SingleJ=round(SingleJ/TotalJ*100,2),MultiJ=round(MultiJ/TotalJ*100,2)) %>%
  plot_ly(x = ~SerialJ, y = ~reorder(PI,Total), type = "bar", name = "Single",  orientation = 'h' ) %>%
    add_trace(x =  ~SingleJ, name = "SMP") %>%
    add_trace(x =  ~MultiJ, name = "Multi") %>%
    layout(xaxis = list(title = '' ), yaxis = list(title = '' ), barmode = 'stack', margin = list(l = 200, r = 20, t = 25, b = 25) )
```  




```{r child = here::here("Rmds","ay1617.Rmd")}
```
	
```{r child = here::here("Rmds","ay1718.Rmd")}
```
	
```{r child = here::here("Rmds","ay1819.Rmd")}
```
	
```{r child = here::here("Rmds","ay1920.Rmd")}
```
	
```{r child = here::here("Rmds","ay2021.Rmd")}
```

```{r child = here::here("Rmds","ay2122.Rmd")}
```

```{r} 
# Add for AY 2223 here
#child = here::here("Rmds","ay2223.Rmd")}
```

```{r child = here::here("Rmds","cy2016.Rmd")}
```
	
```{r child = here::here("Rmds","cy2017.Rmd")}
```
	
```{r child = here::here("Rmds","cy2018.Rmd")}
```
	
```{r child = here::here("Rmds","cy2019.Rmd")}
```
	
```{r child = here::here("Rmds","cy2020.Rmd")}
```

```{r child = here::here("Rmds","cy2021.Rmd")}
```

```{r child = here::here("Rmds","cy2022.Rmd")}
```
 
```{r}
# Add for CY 2023 here
# child = here::here("Rmds","cy2023.Rmd")}
```


 








